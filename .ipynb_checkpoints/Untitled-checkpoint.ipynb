{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/driving_log.csv\")\n",
    "X = data[['center', 'left', 'right']].values\n",
    "y = data['steering'].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(center, left, right, steering_angle):\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return open_image(left), steering_angle + 0.2\n",
    "    elif choice == 1:\n",
    "        return open_image(right), steering_angle - 0.2\n",
    "    return open_image(center), steering_angle\n",
    "\n",
    "\n",
    "def open_image(image_file):\n",
    "    return mpimg.imread(\"./data/\"+image_file.strip())\n",
    "\n",
    "\n",
    "\n",
    "def translate(image, steering_angle, range_x, range_y):\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "  \n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def flip(image, steering_angle):\n",
    "  \n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = - steering_angle\n",
    "    return image, steering_angle\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.resize(image, (320, 160), cv2.INTER_AREA)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    return image\n",
    "\n",
    "def shadow(image):\n",
    "    # (x1, y1) and (x2, y2) forms a line\n",
    "    # xm, ym gives all the locations of the image\n",
    "    x1, y1 = 320 * np.random.rand(), 0\n",
    "    x2, y2 = 320 * np.random.rand(), 160\n",
    "    xm, ym = np.mgrid[0:160, 0:320]\n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "def augument(center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    image, steering_angle = choose( center, left, right, steering_angle)\n",
    "    image, steering_angle = flip(image, steering_angle)\n",
    "    image, steering_angle = translate(image, steering_angle, range_x, range_y)\n",
    "    image = shadow(image)\n",
    "    image = brightness(image)\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "\n",
    "def brightness(image):\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def generator(image_paths, steering_angles, batch_size, training):\n",
    "    images = np.empty([batch_size,160,320,3])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            # argumentation\n",
    "            if training and np.random.rand() < 0.6:\n",
    "                image, steering_angle = augument(center, left, right, steering_angle)\n",
    "            else:\n",
    "                image = open_image(center) \n",
    "            # add the image and steering angle to the batch\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = steering_angle\n",
    "            i = i + 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Cropping2D,Flatten,Dense, Conv2D, MaxPooling2D, Dropout, Lambda\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_4 (Lambda)                (None, 160, 320, 3)   0           lambda_input_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)        (None, 65, 320, 3)    0           lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 35, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 33, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 33, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2112)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           211300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "model.add(Conv2D(24, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "model.add(Conv2D(36, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "model.add(Conv2D(48, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7232/7232 [==============================] - 35s - loss: 0.0181 - val_loss: 0.0144\n",
      "Epoch 2/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0187 - val_loss: 0.0109\n",
      "Epoch 3/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0179 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0175 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0183 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "7232/7232 [==============================] - 34s - loss: 0.0174 - val_loss: 0.0104\n",
      "Epoch 7/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0178 - val_loss: 0.0127\n",
      "Epoch 8/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0169 - val_loss: 0.0128\n",
      "Epoch 9/10\n",
      "7232/7232 [==============================] - 33s - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 10/10\n",
      "7232/7232 [==============================] - 34s - loss: 0.0172 - val_loss: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c20244278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=1e-3))\n",
    "model.fit_generator(generator( X_train, y_train, 64, True), len(X_train),\n",
    "validation_data=generator(X_valid, y_valid, 64, False), nb_val_samples=len(X_valid), nb_epoch=10, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
