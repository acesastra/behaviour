{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/driving_log.csv\")\n",
    "X = data[['center', 'left', 'right']].values\n",
    "y = data['steering'].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(center, left, right, angle):\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return imageo(left), angle + 0.2\n",
    "    elif choice == 1:\n",
    "        return imageo(right), angle - 0.2\n",
    "    return imageo(center), angle\n",
    "\n",
    "\n",
    "def imageo(file):\n",
    "    return mpimg.imread(\"./data/\"+file.strip())\n",
    "\n",
    "\n",
    "\n",
    "def translate(image, angle, rangex, rangey):\n",
    "    transx = rangex * (np.random.rand() - 0.5)\n",
    "    transy = rangey * (np.random.rand() - 0.5)\n",
    "    angle += transx * 0.002\n",
    "    transm = np.float32([[1, 0, transx], [0, 1, transy]])\n",
    "  \n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, transm, (width, height))\n",
    "    return image, angle\n",
    "\n",
    "\n",
    "def flip(image, angle):\n",
    "  \n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        angle = - angle\n",
    "    return image, angle\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.resize(image, (320, 160), cv2.INTER_AREA)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    return image\n",
    "\n",
    "def shadow(image):\n",
    "    x1, y1 = 320 * np.random.rand(), 0\n",
    "    x2, y2 = 320 * np.random.rand(), 160\n",
    "    xmask, ymask = np.mgrid[0:160, 0:320]\n",
    "    masks = np.zeros_like(image[:, :, 1])\n",
    "    masks[(ymask - y1) * (x2 - x1) - (y2 - y1) * (xmask - x1) > 0] = 1\n",
    "    con = masks == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][con] = hls[:, :, 1][con] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "def augument(center, left, right, angle, rangex=100, rangey=10):\n",
    "    image, angle = choose( center, left, right, angle)\n",
    "    image, angle = flip(image, angle)\n",
    "    image, angle = translate(image, angle, rangex, rangey)\n",
    "    image = shadow(image)\n",
    "    image = brightness(image)\n",
    "    return image, angle\n",
    "\n",
    "\n",
    "\n",
    "def brightness(image):\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def generator(image_paths, angles, batch_size, training):\n",
    "    images = np.empty([batch_size,160,320,3])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            angle = angles[index]\n",
    "            # argumentation\n",
    "            if training and np.random.rand() < 0.6:\n",
    "                image, angle = augument(center, left, right, angle)\n",
    "            else:\n",
    "                image = imageo(center) \n",
    "            # add the image and steering angle to the batch\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = angle\n",
    "            i = i + 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Cropping2D,Flatten,Dense, Conv2D, MaxPooling2D, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_3 (Lambda)                (None, 160, 320, 3)   0           lambda_input_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)        (None, 65, 320, 3)    0           lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 3, 35, 64)     27712       convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 1, 33, 64)     36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1, 33, 64)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 2112)          0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 2112)          0           flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 100)           211300      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 100)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 50)            5050        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 50)            0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            510         dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 10)            0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             11          dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2,2),  init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2),  init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2),  init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Conv2D(64, 3, 3, activation='elu',  init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Conv2D(64, 3, 3, activation='elu',  init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='elu', init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='elu', init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='elu', init='he_normal', W_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='linear', init='he_normal'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "24000/24000 [==============================] - 122s - loss: 2.5991 - val_loss: 0.7715\n",
      "Epoch 2/28\n",
      "24000/24000 [==============================] - 121s - loss: 0.9796 - val_loss: 0.7149\n",
      "Epoch 3/28\n",
      "24000/24000 [==============================] - 118s - loss: 0.7807 - val_loss: 0.6632\n",
      "Epoch 4/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.6918 - val_loss: 0.6196\n",
      "Epoch 5/28\n",
      "24000/24000 [==============================] - 119s - loss: 0.6258 - val_loss: 0.5661\n",
      "Epoch 6/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.5640 - val_loss: 0.5102\n",
      "Epoch 7/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.5049 - val_loss: 0.4562\n",
      "Epoch 8/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.4447 - val_loss: 0.3965\n",
      "Epoch 9/28\n",
      "24000/24000 [==============================] - 121s - loss: 0.3839 - val_loss: 0.3347\n",
      "Epoch 10/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.3236 - val_loss: 0.2797\n",
      "Epoch 11/28\n",
      "24000/24000 [==============================] - 121s - loss: 0.2686 - val_loss: 0.2275\n",
      "Epoch 12/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.2155 - val_loss: 0.1820\n",
      "Epoch 13/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.1713 - val_loss: 0.1375\n",
      "Epoch 14/28\n",
      "24000/24000 [==============================] - 119s - loss: 0.1338 - val_loss: 0.1028\n",
      "Epoch 15/28\n",
      "24000/24000 [==============================] - 119s - loss: 0.1042 - val_loss: 0.0733\n",
      "Epoch 16/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0806 - val_loss: 0.0547\n",
      "Epoch 17/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0637 - val_loss: 0.0434\n",
      "Epoch 18/28\n",
      "24000/24000 [==============================] - 119s - loss: 0.0524 - val_loss: 0.0319\n",
      "Epoch 19/28\n",
      "24000/24000 [==============================] - 119s - loss: 0.0445 - val_loss: 0.0290\n",
      "Epoch 20/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0396 - val_loss: 0.0262\n",
      "Epoch 21/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0370 - val_loss: 0.0217\n",
      "Epoch 22/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0345 - val_loss: 0.0216\n",
      "Epoch 23/28\n",
      "24000/24000 [==============================] - 118s - loss: 0.0337 - val_loss: 0.0173\n",
      "Epoch 24/28\n",
      "24000/24000 [==============================] - 118s - loss: 0.0322 - val_loss: 0.0168\n",
      "Epoch 25/28\n",
      "24000/24000 [==============================] - 121s - loss: 0.0316 - val_loss: 0.0163\n",
      "Epoch 26/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0309 - val_loss: 0.0177\n",
      "Epoch 27/28\n",
      "24000/24000 [==============================] - 121s - loss: 0.0315 - val_loss: 0.0177\n",
      "Epoch 28/28\n",
      "24000/24000 [==============================] - 120s - loss: 0.0308 - val_loss: 0.0197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffad7ef2f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=1e-3))\n",
    "model.fit_generator(generator( X_train, y_train, 64, True), 24000,\n",
    "validation_data=generator(X_valid, y_valid, 64, False), nb_val_samples=1024, nb_epoch=28, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
